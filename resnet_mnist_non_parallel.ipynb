{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b11700fa-6ae6-48a9-a6a4-2643b0a07813",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380c20e-84bb-4fb7-a7eb-9e73dff7a378",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55728d43-3480-41ca-973f-5b22dff542d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import os\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d672527-bd2c-4c51-a5f1-b345572f46b8",
   "metadata": {},
   "source": [
    "### MNIST "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cd8e3b4-c814-431b-8d73-2219ddcb22c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders_mnist(batch_size,\n",
    "                           num_workers=0,\n",
    "                           root='data',\n",
    "                           validation_fraction=0.1,\n",
    "                           train_transforms=None,\n",
    "                           test_transforms=None):\n",
    "\n",
    "    if train_transforms is None:\n",
    "        train_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "    if test_transforms is None:\n",
    "        test_transforms = torchvision.transforms.ToTensor()\n",
    "\n",
    "    # Load training data.\n",
    "    train_dataset = torchvision.datasets.MNIST(\n",
    "        root=root,\n",
    "        train=True,\n",
    "        transform=train_transforms,\n",
    "        download=True\n",
    "    )\n",
    "\n",
    "    # Load validation data.\n",
    "    valid_dataset = torchvision.datasets.MNIST(\n",
    "        root=root,\n",
    "        train=True,\n",
    "        transform=test_transforms\n",
    "    )\n",
    "\n",
    "    # Load test data.\n",
    "    test_dataset = torchvision.datasets.MNIST(\n",
    "        root=root,\n",
    "        train=False,\n",
    "        transform=test_transforms\n",
    "    )\n",
    "\n",
    "    # Perform index-based train-validation split of original training data.\n",
    "    total = len(train_dataset)  # Get overall number of samples in original training data.\n",
    "    idx = list(range(total))  # Make index list.\n",
    "    np.random.shuffle(idx)  # Shuffle indices.\n",
    "    vnum = int(validation_fraction * total)  # Determine number of validation samples from validation split.\n",
    "    train_indices, valid_indices = idx[vnum:], idx[0:vnum]  # Extract train and validation indices.\n",
    "\n",
    "    # Get samplers.\n",
    "    train_sampler = torch.utils.data.SubsetRandomSampler(train_indices)\n",
    "    valid_sampler = torch.utils.data.SubsetRandomSampler(valid_indices)\n",
    "\n",
    "    # Get data loaders.\n",
    "    valid_loader = torch.utils.data.DataLoader(\n",
    "        dataset=valid_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        sampler=valid_sampler\n",
    "    )\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        drop_last=True,\n",
    "        sampler=train_sampler\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        dataset=test_dataset,\n",
    "        batch_size=batch_size,\n",
    "        num_workers=num_workers,\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_loader, valid_loader, test_loader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0bf4381-1069-4005-984a-c45f9ce4f634",
   "metadata": {},
   "source": [
    "### ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69295a6c-5a4c-4e96-8ff4-987da7dc7f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(BasicBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != self.expansion * out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, self.expansion * out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(self.expansion * out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "        out += self.shortcut(x)\n",
    "        out = self.relu(out)\n",
    "        return out\n",
    "\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, layers, num_classes):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.in_channels = 64\n",
    "        self.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "\n",
    "        self.layer1 = self.make_layer(block, 64, layers[0])\n",
    "        self.layer2 = self.make_layer(block, 128, layers[1], stride=2)\n",
    "        self.layer3 = self.make_layer(block, 256, layers[2], stride=2)\n",
    "        self.layer4 = self.make_layer(block, 512, layers[3], stride=2)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
    "\n",
    "    def make_layer(self, block, out_channels, blocks, stride=1):\n",
    "        layers = []\n",
    "        layers.append(block(self.in_channels, out_channels, stride))\n",
    "        self.in_channels = out_channels * block.expansion\n",
    "        for _ in range(1, blocks):\n",
    "            layers.append(block(self.in_channels, out_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.maxpool(out)\n",
    "\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "\n",
    "        out = self.avgpool(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc(out)\n",
    "        logits = out\n",
    "        probas = F.softmax(logits, dim=1)\n",
    "        return logits, probas\n",
    "\n",
    "        return out\n",
    "\n",
    "def ResNet18(num_classes):\n",
    "    return ResNet(BasicBlock, [2, 2, 2, 2], num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb14d6c3-dd85-4045-8916-b99fa16d005b",
   "metadata": {},
   "source": [
    "### Training settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d171b9d-041c-4365-8115-f9824e66a228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed): # exclude nondeterminism\n",
    "    os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9b97459-2233-4684-8015-e79f3a5b4e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "batch_size    = 256 \n",
    "num_epochs    = 20 \n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "set_all_seeds(seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6c6cb8f-68e8-4b95-8895-8af371bc07da",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a179604-237c-49a3-97a9-b08f501c166f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image batch dimensions: torch.Size([256, 1, 28, 28])\n",
      "Image label dimensions: torch.Size([256])\n",
      "Class labels of 10 examples: tensor([7, 0, 4, 7, 2, 9, 6, 4, 7, 8])\n"
     ]
    }
   ],
   "source": [
    "train_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),\n",
    "    torchvision.transforms.RandomCrop((64, 64)),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((70, 70)),        \n",
    "    torchvision.transforms.CenterCrop((64, 64)),            \n",
    "    torchvision.transforms.ToTensor(),                \n",
    "    torchvision.transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "train_loader, valid_loader, test_loader = get_dataloaders_mnist(batch_size=batch_size)\n",
    "\n",
    "for images, labels in train_loader:  \n",
    "    print('Image batch dimensions:', images.shape)\n",
    "    print('Image label dimensions:', labels.shape)\n",
    "    print('Class labels of 10 examples:', labels[:10])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e114e3-c33d-4f1d-a7c8-7921571bc6c9",
   "metadata": {},
   "source": [
    "### Training functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "554b355f-cfbc-46bd-aa94-501d22fe8f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_accuracy(model, data_loader, device):\n",
    "\n",
    "    with torch.no_grad(): # Context-manager that disables gradient calculation to reduce memory consumption.\n",
    "\n",
    "        # Initialize number of correctly predicted samples + overall number of samples.\n",
    "        correct_pred, num_samples = 0, 0\n",
    "\n",
    "        for i, (features, targets) in enumerate(data_loader):\n",
    "            features = features.to(device) \n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            result = model(features)\n",
    "            _  , predictions = torch.max(result[0], dim=1)\n",
    "            num_samples += targets.size(0)\n",
    "            correct_pred += (predictions == targets).sum()\n",
    "    \n",
    "    return correct_pred.float() / num_samples * 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3e2db45-320b-45c5-a0fb-60e30167055d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, num_epochs, train_loader,\n",
    "                valid_loader, test_loader, optimizer,\n",
    "                device, logging_interval=50,\n",
    "                scheduler=None):\n",
    "\n",
    "    start = time.time()\n",
    "    loss_fn = F.cross_entropy\n",
    "    \n",
    "    loss_history, train_acc_history, valid_acc_history = [], [], []\n",
    "    \n",
    "    for epoch in range(num_epochs): # Loop over epochs.\n",
    "      \n",
    "        # Training\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (features, targets) in enumerate(train_loader): # Loop over mini batches.\n",
    "            \n",
    "            features = features.to(device) # Convert features and targets to used device.\n",
    "            targets = targets.to(device)\n",
    "            \n",
    "            result = model(features) # Forward pass\n",
    "            loss = loss_fn(result[0], targets)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            loss.backward() # Backward pass\n",
    "            \n",
    "            optimizer.step() # Update model parameters\n",
    "            \n",
    "            loss_history.append(loss.item())\n",
    "            \n",
    "            if not batch_idx % logging_interval:\n",
    "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
    "                      f'| Loss: {loss:.4f}')\n",
    "                \n",
    "        # Validation\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        with torch.no_grad(): \n",
    "            \n",
    "            train_acc = compute_accuracy(model, train_loader, device)\n",
    "            valid_acc = compute_accuracy(model, valid_loader, device)\n",
    "            \n",
    "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
    "                  f'| Train: {train_acc :.2f}% '\n",
    "                  f'| Validation: {valid_acc :.2f}%')\n",
    "            \n",
    "            valid_acc_history.append(valid_acc)\n",
    "            train_acc_history.append(train_acc)\n",
    "            \n",
    "        elapsed = time.time() - start\n",
    "        print(f'Time elapsed: {elapsed:.2f}s')\n",
    "        \n",
    "        if scheduler is not None: scheduler.step(valid_acc_history[-1])\n",
    "        \n",
    "    elapsed = time.time() - start\n",
    "    print(f'Total Training Time: {elapsed:.2f}s')\n",
    "    \n",
    "    \n",
    "    \n",
    "    test_acc = compute_accuracy(model, test_loader, device)\n",
    "    print(f'Test accuracy: {test_acc :.2f}%')\n",
    "    \n",
    "    return loss_history, train_acc_history, valid_acc_history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5ade41-e1d2-4cc5-91a8-ba3272f6b258",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4434bf33-0c02-495f-8a76-8e874299d230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/020 | Batch 0000/0210 | Loss: 2.5828\n",
      "Epoch: 001/020 | Batch 0050/0210 | Loss: 0.1752\n",
      "Epoch: 001/020 | Batch 0100/0210 | Loss: 0.1288\n",
      "Epoch: 001/020 | Batch 0150/0210 | Loss: 0.0503\n",
      "Epoch: 001/020 | Batch 0200/0210 | Loss: 0.0782\n",
      "Epoch: 001/020 | Train: 97.41% | Validation: 96.97%\n",
      "Time elapsed: 16.33s\n",
      "Epoch: 002/020 | Batch 0000/0210 | Loss: 0.0508\n",
      "Epoch: 002/020 | Batch 0050/0210 | Loss: 0.0427\n",
      "Epoch: 002/020 | Batch 0100/0210 | Loss: 0.0700\n",
      "Epoch: 002/020 | Batch 0150/0210 | Loss: 0.0415\n",
      "Epoch: 002/020 | Batch 0200/0210 | Loss: 0.0316\n",
      "Epoch: 002/020 | Train: 98.60% | Validation: 98.25%\n",
      "Time elapsed: 27.48s\n",
      "Epoch: 003/020 | Batch 0000/0210 | Loss: 0.0259\n",
      "Epoch: 003/020 | Batch 0050/0210 | Loss: 0.0563\n",
      "Epoch: 003/020 | Batch 0100/0210 | Loss: 0.0754\n",
      "Epoch: 003/020 | Batch 0150/0210 | Loss: 0.0599\n",
      "Epoch: 003/020 | Batch 0200/0210 | Loss: 0.0471\n",
      "Epoch: 003/020 | Train: 99.06% | Validation: 98.57%\n",
      "Time elapsed: 38.72s\n",
      "Epoch: 004/020 | Batch 0000/0210 | Loss: 0.0707\n",
      "Epoch: 004/020 | Batch 0050/0210 | Loss: 0.0056\n",
      "Epoch: 004/020 | Batch 0100/0210 | Loss: 0.0796\n",
      "Epoch: 004/020 | Batch 0150/0210 | Loss: 0.0370\n",
      "Epoch: 004/020 | Batch 0200/0210 | Loss: 0.0125\n",
      "Epoch: 004/020 | Train: 99.30% | Validation: 98.83%\n",
      "Time elapsed: 49.83s\n",
      "Epoch: 005/020 | Batch 0000/0210 | Loss: 0.0235\n",
      "Epoch: 005/020 | Batch 0050/0210 | Loss: 0.0171\n",
      "Epoch: 005/020 | Batch 0100/0210 | Loss: 0.0100\n",
      "Epoch: 005/020 | Batch 0150/0210 | Loss: 0.0338\n",
      "Epoch: 005/020 | Batch 0200/0210 | Loss: 0.0162\n",
      "Epoch: 005/020 | Train: 99.57% | Validation: 99.07%\n",
      "Time elapsed: 60.89s\n",
      "Epoch: 006/020 | Batch 0000/0210 | Loss: 0.0227\n",
      "Epoch: 006/020 | Batch 0050/0210 | Loss: 0.0167\n",
      "Epoch: 006/020 | Batch 0100/0210 | Loss: 0.0209\n",
      "Epoch: 006/020 | Batch 0150/0210 | Loss: 0.0413\n",
      "Epoch: 006/020 | Batch 0200/0210 | Loss: 0.0199\n",
      "Epoch: 006/020 | Train: 99.23% | Validation: 98.53%\n",
      "Time elapsed: 71.92s\n",
      "Epoch: 007/020 | Batch 0000/0210 | Loss: 0.0136\n",
      "Epoch: 007/020 | Batch 0050/0210 | Loss: 0.0127\n",
      "Epoch: 007/020 | Batch 0100/0210 | Loss: 0.0125\n",
      "Epoch: 007/020 | Batch 0150/0210 | Loss: 0.0394\n",
      "Epoch: 007/020 | Batch 0200/0210 | Loss: 0.0070\n",
      "Epoch: 007/020 | Train: 99.45% | Validation: 98.72%\n",
      "Time elapsed: 82.98s\n",
      "Epoch: 008/020 | Batch 0000/0210 | Loss: 0.0020\n",
      "Epoch: 008/020 | Batch 0050/0210 | Loss: 0.0006\n",
      "Epoch: 008/020 | Batch 0100/0210 | Loss: 0.0390\n",
      "Epoch: 008/020 | Batch 0150/0210 | Loss: 0.0167\n",
      "Epoch: 008/020 | Batch 0200/0210 | Loss: 0.0029\n",
      "Epoch: 008/020 | Train: 99.67% | Validation: 98.80%\n",
      "Time elapsed: 94.10s\n",
      "Epoch: 009/020 | Batch 0000/0210 | Loss: 0.0028\n",
      "Epoch: 009/020 | Batch 0050/0210 | Loss: 0.0025\n",
      "Epoch: 009/020 | Batch 0100/0210 | Loss: 0.0036\n",
      "Epoch: 009/020 | Batch 0150/0210 | Loss: 0.0167\n",
      "Epoch: 009/020 | Batch 0200/0210 | Loss: 0.0013\n",
      "Epoch: 009/020 | Train: 99.51% | Validation: 98.80%\n",
      "Time elapsed: 105.23s\n",
      "Epoch: 010/020 | Batch 0000/0210 | Loss: 0.0039\n",
      "Epoch: 010/020 | Batch 0050/0210 | Loss: 0.0017\n",
      "Epoch: 010/020 | Batch 0100/0210 | Loss: 0.0096\n",
      "Epoch: 010/020 | Batch 0150/0210 | Loss: 0.0072\n",
      "Epoch: 010/020 | Batch 0200/0210 | Loss: 0.0139\n",
      "Epoch: 010/020 | Train: 99.56% | Validation: 98.73%\n",
      "Time elapsed: 116.31s\n",
      "Epoch: 011/020 | Batch 0000/0210 | Loss: 0.0041\n",
      "Epoch: 011/020 | Batch 0050/0210 | Loss: 0.0061\n",
      "Epoch: 011/020 | Batch 0100/0210 | Loss: 0.0137\n",
      "Epoch: 011/020 | Batch 0150/0210 | Loss: 0.0069\n",
      "Epoch: 011/020 | Batch 0200/0210 | Loss: 0.0142\n",
      "Epoch: 011/020 | Train: 99.84% | Validation: 99.03%\n",
      "Time elapsed: 127.34s\n",
      "Epoch: 012/020 | Batch 0000/0210 | Loss: 0.0007\n",
      "Epoch: 012/020 | Batch 0050/0210 | Loss: 0.0011\n",
      "Epoch: 012/020 | Batch 0100/0210 | Loss: 0.0098\n",
      "Epoch: 012/020 | Batch 0150/0210 | Loss: 0.0024\n",
      "Epoch: 012/020 | Batch 0200/0210 | Loss: 0.0159\n",
      "Epoch: 012/020 | Train: 99.78% | Validation: 99.07%\n",
      "Time elapsed: 138.50s\n",
      "Epoch: 013/020 | Batch 0000/0210 | Loss: 0.0007\n",
      "Epoch: 013/020 | Batch 0050/0210 | Loss: 0.0016\n",
      "Epoch: 013/020 | Batch 0100/0210 | Loss: 0.0022\n",
      "Epoch: 013/020 | Batch 0150/0210 | Loss: 0.0031\n",
      "Epoch: 013/020 | Batch 0200/0210 | Loss: 0.0141\n",
      "Epoch: 013/020 | Train: 99.80% | Validation: 98.92%\n",
      "Time elapsed: 149.59s\n",
      "Epoch: 014/020 | Batch 0000/0210 | Loss: 0.0002\n",
      "Epoch: 014/020 | Batch 0050/0210 | Loss: 0.0013\n",
      "Epoch: 014/020 | Batch 0100/0210 | Loss: 0.0065\n",
      "Epoch: 014/020 | Batch 0150/0210 | Loss: 0.0020\n",
      "Epoch: 014/020 | Batch 0200/0210 | Loss: 0.0132\n",
      "Epoch: 014/020 | Train: 99.86% | Validation: 98.97%\n",
      "Time elapsed: 160.65s\n",
      "Epoch: 015/020 | Batch 0000/0210 | Loss: 0.0019\n",
      "Epoch: 015/020 | Batch 0050/0210 | Loss: 0.0020\n",
      "Epoch: 015/020 | Batch 0100/0210 | Loss: 0.0053\n",
      "Epoch: 015/020 | Batch 0150/0210 | Loss: 0.0051\n",
      "Epoch: 015/020 | Batch 0200/0210 | Loss: 0.0008\n",
      "Epoch: 015/020 | Train: 99.82% | Validation: 99.07%\n",
      "Time elapsed: 171.71s\n",
      "Epoch: 016/020 | Batch 0000/0210 | Loss: 0.0133\n",
      "Epoch: 016/020 | Batch 0050/0210 | Loss: 0.0023\n",
      "Epoch: 016/020 | Batch 0100/0210 | Loss: 0.0028\n",
      "Epoch: 016/020 | Batch 0150/0210 | Loss: 0.0007\n",
      "Epoch: 016/020 | Batch 0200/0210 | Loss: 0.0009\n",
      "Epoch: 016/020 | Train: 99.88% | Validation: 99.02%\n",
      "Time elapsed: 182.83s\n",
      "Epoch 00016: reducing learning rate of group 0 to 1.0000e-02.\n",
      "Epoch: 017/020 | Batch 0000/0210 | Loss: 0.0001\n",
      "Epoch: 017/020 | Batch 0050/0210 | Loss: 0.0001\n",
      "Epoch: 017/020 | Batch 0100/0210 | Loss: 0.0001\n",
      "Epoch: 017/020 | Batch 0150/0210 | Loss: 0.0002\n",
      "Epoch: 017/020 | Batch 0200/0210 | Loss: 0.0007\n",
      "Epoch: 017/020 | Train: 99.98% | Validation: 99.20%\n",
      "Time elapsed: 193.81s\n",
      "Epoch: 018/020 | Batch 0000/0210 | Loss: 0.0059\n",
      "Epoch: 018/020 | Batch 0050/0210 | Loss: 0.0002\n",
      "Epoch: 018/020 | Batch 0100/0210 | Loss: 0.0003\n",
      "Epoch: 018/020 | Batch 0150/0210 | Loss: 0.0014\n",
      "Epoch: 018/020 | Batch 0200/0210 | Loss: 0.0002\n",
      "Epoch: 018/020 | Train: 99.99% | Validation: 99.23%\n",
      "Time elapsed: 204.79s\n",
      "Epoch: 019/020 | Batch 0000/0210 | Loss: 0.0046\n",
      "Epoch: 019/020 | Batch 0050/0210 | Loss: 0.0003\n",
      "Epoch: 019/020 | Batch 0100/0210 | Loss: 0.0001\n",
      "Epoch: 019/020 | Batch 0150/0210 | Loss: 0.0003\n",
      "Epoch: 019/020 | Batch 0200/0210 | Loss: 0.0001\n",
      "Epoch: 019/020 | Train: 99.99% | Validation: 99.22%\n",
      "Time elapsed: 215.75s\n",
      "Epoch: 020/020 | Batch 0000/0210 | Loss: 0.0002\n",
      "Epoch: 020/020 | Batch 0050/0210 | Loss: 0.0002\n",
      "Epoch: 020/020 | Batch 0100/0210 | Loss: 0.0005\n",
      "Epoch: 020/020 | Batch 0150/0210 | Loss: 0.0001\n",
      "Epoch: 020/020 | Batch 0200/0210 | Loss: 0.0002\n",
      "Epoch: 020/020 | Train: 99.99% | Validation: 99.20%\n",
      "Time elapsed: 226.82s\n",
      "Total Training Time: 226.82s\n",
      "Test accuracy: 99.29%\n"
     ]
    }
   ],
   "source": [
    "model = ResNet18(num_classes=10)\n",
    "model = model.to(device)\n",
    "\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.1, momentum=0.9)  \n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor=0.1, mode='max', verbose=True)\n",
    "\n",
    "loss_list, train_acc_list, valid_acc_list = [], [], []\n",
    "loss_list, train_acc_list, valid_acc_list = train_model(model=model, \n",
    "                                                        num_epochs=num_epochs,\n",
    "                                                        train_loader=train_loader, \n",
    "                                                        valid_loader=valid_loader, \n",
    "                                                        test_loader=test_loader,\n",
    "                                                        optimizer=optimizer,\n",
    "                                                        device=device, \n",
    "                                                        scheduler=scheduler,\n",
    "                                                        logging_interval=50)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (2024-venv)",
   "language": "python",
   "name": "2024-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
